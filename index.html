<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Cody Reading</title>

  <meta name="author" content="Cody Reading">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Cody Reading</name>
              </p>
              <p>I am a PhD student at <a href="https://www.sfu.ca/">Simon Fraser University</a>  supervised by <a href=https://taiya.github.io">Andrea Tagliasacchi</a>,  My research interests are in 3D computer vision, generative models, and computer graphics. and. I am currently interested in using machine learning for 3D content creation and editing.
              </p>
              <p>
               I received my master's degree from the  <a href="https://www.utoronto.ca/">University of Toronto</a> supervised by <a href="https://www.trailab.utias.utoronto.ca/stevenwaslander">Steven Waslander</a>,
               and received my bachelor's degree from the  <a href="https://uwaterloo.ca/">University of Waterloo</a>.
               I also worked at <a href="https://monstersaliensrobotszombies.com/">MARZ</a>  developing <a href="https://monstersaliensrobotszombies.com/vanityai">Vanity AI</a>, an AI solution for facial editing for VFX.
              </p>
              <p style="text-align:center">
                <a href="mailto:codyreading@gmail.com"><i class="fas fa-envelope"></i> Email</a> &nbsp;/&nbsp;
                <a href="data/CodyReading-Resume.pdf"><i class="fas fa-file-pdf"></i> CV</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.ca/citations?user=VqvADvQAAAAJ&hl=en"><i class="ai ai-google-scholar-square ai-lg"></i> Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://twitter.com/code_red7777"><i class="fab fa-twitter"></i> Twitter</a> &nbsp;/&nbsp;
                <a href="https://github.com/codyreading/"><i class="fab fa-github"></i> Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/CodyReading.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/CodyReading_Circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="bayes_rays_stop()" onmouseover="bayes_rays_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='bayes_rays_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/bayes_rays.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/bayes_rays.png' width="160">
              </div>
              <script type="text/javascript">
                function bayes_rays_start() {
                  document.getElementById('bayes_rays_image').style.opacity = "1";
                }

                function bayes_rays_stop() {
                  document.getElementById('bayes_rays_image').style.opacity = "0";
                }
                bayes_rays_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://bayesrays.github.io/">
                <papertitle>Bayes' Rays: Uncertainty Quantification for Neural Radiance Fields</papertitle>
              </a>
              <br>
              <a href="https://lilygoli.github.io/">Lily Goli</a>,
              <strong>Cody Reading</strong>,
              <a href="https://www.silviasellan.com/">Silvia Sell√°n</a>,
              <a href="https://www.cs.toronto.edu/~jacobson/">Alec Jacobson</a>,
							<a href="https://taiya.github.io/">Andrea Tagliasacchi</a>
              <br>
              <em>CVPR</em>, 2024 <font color="red"><strong>(Highlight)</strong></font>
              <br>
              <a href="https://bayesrays.github.io/">Project Page</a>
              /
              <a href="https://arxiv.org/abs/2309.03185">arXiv</a>
              /
              <a href="https://github.com/BayesRays/BayesRays">Code</a>
              <p></p>
              <p>
              We introduce a post-hoc framework to evaluate uncertainty in any pre-trained NeRF without modifying the training process.
              </p>
            </td>
          </tr>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="banf_stop()" onmouseover="banf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='banf_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/banf.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/banf.png' width="160">
                </div>
                <script type="text/javascript">
                  function banf_start() {
                    document.getElementById('banf_image').style.opacity = "1";
                  }

                  function banf_stop() {
                    document.getElementById('banf_image').style.opacity = "0";
                  }
                  banf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://theialab.github.io/banf/">
                  <papertitle>BANF: Band-limited Neural Fields for Levels of Detail Reconstruction</papertitle>
                </a>
                <br>
                <a href="https://ahanio.github.io/">Ahan Shabanov</a>,
                <a href="https://shrisudhang.github.io/">Shrisudhan Govindarajan</a>,
                <strong>Cody Reading</strong>,
                <a href="https://lilygoli.github.io/">Lily Goli</a>,
                <a href="http://drebain.com/">Daniel Rebain</a>,
                <a href="https://www.cs.ubc.ca/~kmyi/">Kwang Moo Yi</a>
                <a href="https://taiya.github.io/">Andrea Tagliasacchi</a>
                <br>
                <em>CVPR</em>, 2024
                <br>
                <a href="https://theialab.github.io/banf/">Project Page</a>
                /
                <a href="https://theialab.github.io/banf/paper.pdf">Paper</a>
                <p></p>
                <p>
                We introduce BANF, a method for band-limited frequency decomposition in neural fields.
                </p>
              </td>
            </tr>
          <tr onmouseout="intertrack_stop()" onmouseover="intertrack_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='intertrack_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/intertrack.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/intertrack.png' width="160">
              </div>
              <script type="text/javascript">
                function intertrack_start() {
                  document.getElementById('intertrack_image').style.opacity = "1";
                }

                function intertrack_stop() {
                  document.getElementById('intertrack_image').style.opacity = "0";
                }
                intertrack_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2208.08041">
                <papertitle>InterTrack: Interaction Transformer for 3D Multi-Object Tracking</papertitle>
              </a>
              <br>
              <a href="https://www.trailab.utias.utoronto.ca/john-willes">John Willes*</a>,
              <strong>Cody Reading*</strong>,
							<a href="https://www.trailab.utias.utoronto.ca/stevenwaslander">Steven Waslander</a>
              <br>
              <em>CRV</em>, 2023 <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2208.08041">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=81hZcZcSsBA&ab_channel=trailab">Video</a>
              <p></p>
              <p>
              We introduce the Interaction Transformer to 3D multi-object tracking to generate discriminative object representations for data association.
              </p>
            </td>
          </tr>
          <tr onmouseout="caddn_stop()" onmouseover="caddn_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='caddn_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/caddn.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/caddn.png' width="160">
              </div>
              <script type="text/javascript">
                function caddn_start() {
                  document.getElementById('caddn_image').style.opacity = "1";
                }

                function caddn_stop() {
                  document.getElementById('caddn_image').style.opacity = "0";
                }
                caddn_stop()
              </script>
            </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://trailab.github.io/CaDDN/">
                <papertitle>Categorical Depth Distribution Network for Monocular 3D Object Detection</papertitle>
              </a>
              <br>
              <strong>Cody Reading</strong>,
              <a href="https://www.aharakeh.com/">Ali Harakeh</a>,
              <a href="https://juliachae.github.io/">Julia Chae</a>,
              <a href="https://www.trailab.utias.utoronto.ca/stevenwaslander">Steven Waslander</a>
              <br>
              <em>CVPR</em>, 2021 <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://trailab.github.io/CaDDN/">Project Page</a>
              /
              <a href="https://arxiv.org/abs/2103.01100">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=E3NoO_c6tPg&t=3s&ab_channel=trailab">Video</a>
              /
              <a href="https://github.com/TRAILab/CaDDN">Code</a>
              <p></p>
              <p>
              We estimate categorical depth distributions to project image feature information to 3D space for improved 3D monocular object detection.
              </p>
            </td>
          </tr>
          <tr onmouseout="ursa_stop()" onmouseover="ursa_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ursa_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/ursa.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/ursa.png' width="160">
              </div>
              <script type="text/javascript">
                function ursa_start() {
                  document.getElementById('ursa_image').style.opacity = "1";
                }

                function ursa_stop() {
                  document.getElementById('ursa_image').style.opacity = "0";
                }
                ursa_stop()
              </script>
            </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://uwaterloo.ca/waterloo-intelligent-systems-engineering-lab/ursa">
                <papertitle>Unlimited Road-scene Synthetic Annotation (URSA) Dataset</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.ca/citations?user=ymEYdWYAAAAJ&hl=en&oi=sra">Matt Angus</a>,
              <a href="https://www.linkedin.com/in/mohamed-elbalkini-946408137/">Mohamed ElBalkini</a>,
              <a href="https://scholar.google.ca/citations?user=Dzf0l6QAAAAJ&hl=en">Samin Khan</a>,
              <a href="https://www.aharakeh.com/">Ali Harakeh</a>,
              <a href="http://andrienko.ca/">Oles Andrienko</a>,
              <strong>Cody Reading</strong>,
              <a href="https://www.trailab.utias.utoronto.ca/stevenwaslander">Steven Waslander</a>,
              <a href="https://gsd.uwaterloo.ca/kczarnec">Krzysztof Czarnecki</a>
              <br>
              <em>ITSC</em>, 2018
              <br>
              <a href="https://uwaterloo.ca/waterloo-intelligent-systems-engineering-lab/ursa">Project Page</a>
              /
              <a href="https://arxiv.org/abs/1807.06056">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=Z6q1x-IGj_4&ab_channel=MohamedElBalkini">Video</a>
              /
              <a href="https://uwaterloo.ca/waterloo-intelligent-systems-engineering-lab/ursa-data">Dataset</a>
              <p></p>
              <p>
              We generate a synthetic dataset for semantic segmentation based on GTA V.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Experience</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/SFU.png" alt="sfu" width="160" height="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">3D Content Creation Researcher</span>
            <br>
            <a href="https://www.sfu.ca/">Simon Fraser University</a>
            <br>
              Sept. 2023 - Present
            <br>
            <em>PhD Candidate, Computing Science</em>
            <br>
            <p>Implementing novel techniques in 3D content creation and generative models, involving optimizing NeRF and 3D Gaussian representations with diffusion guidance.</p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/MARZ.jpeg" alt="sfu" width="160" height="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">Machine Learning Research Associate</span>
            <br>
            <a href="https://monstersaliensrobotszombies.com/">Monsters Aliens Robots Zombies</a>
            <br>
              Jan. 2022 - Aug. 2023
            <br>
            <p>Developed a facial de-aging tool Vanity AI designed for VFX applications, achieving 300x speed up compared to traditional VFX workflows.</p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/UofT.png" alt="sfu" width="160" height="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">3D Perception Researcher</span>
            <br>
            <a href="https://www.utoronto.ca/">University of Toronto</a>
            <br>
              Sept. 2019 - Dec. 2021
            <br>
            <em>Master‚Äôs of Applied Science, Aerospace Engineering </em>
            <br>
            <p> Innovated methodologies in autonomous vehicle 3D perception, achieving 1st and 2nd place on 3D monocular object detection and 3D multi-object tracking benchmarks respectively</p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/NVIDIA.jpeg" alt="sfu" width="160" height="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">Software Engineer - Autonomous Driving</span>
            <br>
            <a href="https://www.nvidia.com/en-us/">NVIDIA Corporation</a>
            <br>
              Jan. 2018 - Aug. 2018
            <br>
            <p> Developed a vehicle trajectory generation library within the NVIDIA DriveWorks SDK using C++ to generate a sequence of vehicle poses from GPS, IMU, and CAN sensor data</p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/Uwaterloo.png" alt="sfu" width="160" height="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">Semantic Segmentation Research Co-op</span>
            <br>
            <a href="https://uwaterloo.ca/">University of Waterloo</a>
            <br>
              May 2017 - Aug. 2017
            <br>
            <p> Developed semantic segmentation training infrastructure to support unified training of the SegNet and FCN methods on the Cityscapes, Playing-for-data, and Synthia datasets.</p>
          </td>
        </tr>
      </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website template from <a href="https://jonbarron.info/">Jon Barron</a>.
                <br> Last updated: April, 2024
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
